{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNbl9TP5NGkQa8Rj/3XI5pC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GydeokLee/dl23/blob/main/%EB%94%94%EC%A7%80%ED%84%B8%EB%A6%AC%ED%84%B0%EB%9F%AC%EC%8B%9C%20%EC%B0%B8%EA%B3%A0%EC%9E%90%EB%A3%8C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.\tGTTS 설치 코드 : !pip install Gtts\n",
        "                 !pip install iPython\n",
        "1.\tFrom gtts import gtts\n",
        "2.\t오디오 설치 코드: from IPython.display import Audio 이 줄까지는 기본적으로 해야함\n",
        "1.\tdef tts(text):\n",
        "2.\tgtts_object = gTTs(text, lang = “en” , slow = True)\n",
        "3.\tgtts_object.save(:myaudio.mp3”)\n",
        "4.\treturn Audio(“myaudio.mp3”) 여기까지 오디오 파일 만들기\n",
        "5.\t이까지 했으면 오디오 재생 할 때 tts(‘something”) 새 코드에 만들면 됨.\n",
        "6.\tmytext = input(“Type text to generate audio: “)\n",
        "7.\ttts(mytext) 하면 내가 입력하는 언어를 재생할 수 있게 입력창이 나오는 코드가 생성이 된다’. Etts, ktts, ftts(“something”)을 코드로 만들면 그 언어에 맞는 언어 파일이 재생된다.\n",
        "8.\t#은 인간만이 알아들을 수 있는 말이다\n"
      ],
      "metadata": {
        "id": "-A64bV1TRi_Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.  variation: 변수, 코딩할 때 필요한 변수를 지정하는 것\n",
        "            Ex) x1 = 10\n",
        "               y1 “Hello, class!” 이렇게 정의를 할 수 있다\n",
        "“” 는 코딩 시에 인간이 알아들을 수 있는 언어를 의미한다 안하면 컴퓨터는 컴퓨터 언어로 알아듣는다.\n",
        "x1 = x + 10 이라는 식을 코딩하면 100이라는 값이 나온다\n",
        "y1 = y + “Welcome to the class.” 라고 넣으면 hello, class! Welcome to the class. 라고 나온다 이때 띄어쓰기 하고 싶으면 ‘” 넣으면 띄어쓰기 가능\n",
        "계산식은 x1 = 2;  y = 5\n",
        "         a1 = x +, -, * /를 사용하면 되고, **는 거듭제곱을 의미하는 것이다.\n",
        "Print(something)을 맨 밑에 넣으면 해당되는 식에 대한 결과값이 나온다\n",
        "def add(x, y): 는 더하기\n"
      ],
      "metadata": {
        "id": "rdaQzBOLRnbj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "return x + y\n",
        "def subtract(x, y): 는 빼기\n",
        "return x- y\n",
        "def multiply(x, y) 는 곱하기\n",
        "return x * y\n",
        "def divide(x, y): 는 나누기 라고 정의를 해두면\n",
        "return x / y\n",
        "add(2,3), subtract(2,3), multiply(2,3), divide(3,1) 라고 코드 짜넣으면 된다\n",
        "\n",
        "Data type에는 여러가지가 있는데\n",
        "Number에는 int, float이 있는데 int는 정수, float는 소수이다\n",
        "String은 string 문자를 말하는 거임\n",
        "List는 여러가지 문자들이 있는 수열을 말하는 것이다\n",
        "Dictionary는 키(KEY)와 값(VALUE) 쌍을 포함하는 데이터임 이거 가지고 학생들 점수를 관리하는 거임\n",
        "Tuple은 변경할 수 없는 순서형 데이터 구조 리스트랑 비슷하지만 한 번 생성된 튜플은 변경할 수 없음\n",
        "Type()는 괄호 안에 있는 것이 뭔 지 알려주는 거임 int인지 str인지 알려줌\n",
        "List는 a = 안에 있는 구성요소들을 가지고 있는 것을 말하는 거임\n",
        "random.randint(1, 10)랜덤으로 숫자를 나오게 할 수 있는 함수\n",
        "[]: list를 말하는 거임\n"
      ],
      "metadata": {
        "id": "fQQhCktLRw1l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "API: application programming interface\n",
        "GPT: Generative Pre-trained Transformer\n",
        "한 함수에 대해서 정의를 해 두고, x3 = range(1, 10) 라고 하면 안에 있는거 다 나옴\n",
        "                               List(x3)\n",
        "\n",
        "Mydict = {}라고 정의 해둠\n",
        "Yournumber = input(something) 이라고 해두면 자신의 번호를 입력하면 번호 나오게 할 수 있음\n",
        "Int, str으로 바꾸면 그걸로 바꿀 수 있으니까\n",
        "String은 integer로 바꿀 수 없다 integer는 string으로 바꿀 수 있다. “”로 하면 됨\n",
        "Yournumber = int”(yournumber”)이라고 바꾸면 int라고 인식을 하니까 그렇게 알면 됨\n",
        "Ex) day = input(“How many days?: “)\n",
        "Num_day = int(day)\n",
        "     Hours = 24\n",
        "     Total = num_day * hours\n",
        "     Print(“The total hours passed since Mary met John are: “, total, “hours.”)\n"
      ],
      "metadata": {
        "id": "HqrrhE8HR7yp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strip()은 공백이나 tabs 같은 것들을 없애 주는 역할이다\n",
        "w1.split()은 안에 있는 것들 space 기준으로 나눠주는 거임\n",
        "join은 합쳐주는 것을 말하는 거임\n",
        "‘-‘,join(wordlist) 이런 식으로 설정하면 된다\n",
        "w1.lower() 소문자\n",
        "w1.upper() 대문자\n",
        "len(w1) : string의 길이\n",
        "w1[0] 은 첫번째\n",
        "-1은 뒤에서부터\n",
        "0:은 0부터 오른쪽에 있는거 다\n",
        ":은 싹 다\n",
        "1:3은 1부터 3까지 오른쪽은 포함하지 않는다\n",
        "Numbers = [1,2,3,4,5]\n",
        "Squared = []\n",
        "For I in numbers:\n",
        "S = I ** 2\n",
        "Squared.append(s)\n",
        "Print(squared)\n",
        "Append()는 부록처럼 들어가는 것을 말한다\n"
      ],
      "metadata": {
        "id": "aeKZMSVGR_Wk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "W = “Mary is friendly”\n",
        "A = w.split()\n",
        "W1 = a[0]\n",
        "W2 = a[1]\n",
        "W3 = a[2]\n",
        "Nw1 = nw1 + “ “ + w1 + “ ” +w3\n",
        "\n",
        "S1 = s[‘-1]\n",
        "S2 = s1 + “?”; s2\n"
      ],
      "metadata": {
        "id": "wQldiMJKSEVe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import nltk\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "url = 여기에 링크만 넣으먄 된다\n",
        "os.system(\"curl \" + url + \" > RE.ch05.txt\")\n",
        "#@markdown 🌀 read a text file in the server: as _text_\n",
        "file = open(\"RE.ch05.txt\")\n",
        "text = file.read().replace(\"\\n\", \" \")\n",
        "file.close()\n",
        "\n",
        "markdown부터 file까지 지우면 제목없이 그림만 나온\n",
        "\n",
        "wc = WordCloud().generate(text)\n",
        "plt.imshow(wc)"
      ],
      "metadata": {
        "id": "g_gSe8f_SRNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "# Getting text from the user\n",
        "user_text = input(\"Please paste your text here: \")\n",
        "\n",
        "\n",
        "wordcloud = WordCloud(\n",
        "    background_color='white',\n",
        "    width=800,\n",
        "    height=800,\n",
        "    max_words=100\n",
        ").generate(user_text)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U7Qo2J7gSgTj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "단어 별로 split하는 방법: example_string제시\n",
        "                set1 = example_string.split()\n",
        "                print(set1) 하기\n",
        "문장 별로 split하는 방법: set2 = example_string.split(\".\")\n",
        "set2\n",
        "\n",
        "Strip() 하는 방법\n",
        "\n",
        "set3 = [s.strip() for s in set2]\n",
        "set3"
      ],
      "metadata": {
        "id": "kKGq9DwjSgQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk library 사용하는 법\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "slist = sent_tokenize(example_string)\n",
        "slist[0]\n",
        "\n",
        "텍스트 넣으면 몇 개인지 세\n",
        "mytext=input(\"Paste text: \")\n",
        "slist1 = sent_tokenize(mytext)\n",
        "slist1[50]\n",
        "\n",
        "mywords = word_tokenize(mytext)\n",
        "print(len(mywords))\n",
        "mywords[100]\n"
      ],
      "metadata": {
        "id": "7u9a6_r-Ubah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "sample = \"Sir, I protest. I am not a merry man!\"\n",
        "s1 = word_tokenize(sample); s1\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "w1 = \"Mary\"\n",
        "w2 = \"susan\"\n",
        "w1.casefold(): 모든 문자를 소문자화해서 비교하기 쉽게함\n",
        "\n",
        "이러면 sir, protest, merry, man만 남는\n",
        "filtered_list = []\n",
        "\n",
        "for word in s1:\n",
        "   if (word.casefold() not in stop_words) & (len(word)>1):\n",
        "        filtered_list.append(word)\n",
        "\n",
        "filtered_list\n",
        "\n",
        "이러면 english의 조건에 부합하는거 빼고 나\n",
        "w1 = word_tokenize(text1)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "w2 = [w for w in w1 if w.lower() not in stop_words and len(w) > 2]\n",
        "w2\n",
        "\n",
        "추가하기\n",
        "additional_stopwords = {'one', 'day', 'upon'}\n",
        "stop_words = set(stopwords.words('english') + list(additional_stopwords))\n",
        "w1 = word_tokenize(text1)\n",
        "stop_words = set(stopwords.words('english') + list(additional_stopwords))\n",
        "\n",
        "w2 = [w for w in w1 if w.lower() not in stop_words and len(w) > 2]\n",
        "w2\n",
        "\n",
        "Tagging\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "sentence = input(\"Type your sentence: \")\n",
        "mywords = word_tokenize(sentence)\n",
        "nltk.pos_tag(mywords)\n",
        "\n",
        "nltk.download('tagsets')\n",
        "\n",
        "\n",
        "from nltk.book import *\n",
        "\n",
        "\n",
        "text8.concordance(\"man\")\n",
        "\n",
        "import nltk\n",
        "\n",
        "# Define some plain text\n",
        "text = input(\"Paste your text: \")\n",
        "\n",
        "# Tokenize the text into a list of words\n",
        "tokens = nltk.word_tokenize(text)\n",
        "\n",
        "# Create an nltk.Text object from the list of tokens\n",
        "text_object = nltk.Text(tokens)\n",
        "\n",
        "# Use the concordance method to find occurrences of the word \"fox\"\n",
        "text_object.concordance(\"be\")"
      ],
      "metadata": {
        "id": "AfKVNwkeVwFO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "nltk 가져오\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "마침표빼고 글자 수 체크하\n",
        "words = word_tokenize(text)\n",
        "wordlist = []\n",
        "for w in words:\n",
        "  if len(w) > 2:\n",
        "    wordlist.append(w)\n",
        "    print('Total words including punctuation: ', len(words))\n",
        "print('Total words: ', len(wordlist))\n",
        "print(wordlist)\n",
        "\n",
        "다 소문자화\n",
        "owerword = []\n",
        "\n",
        "for w in wordlist:\n",
        "  w1 = w.lower()\n",
        "  lowerword.append(w1)\n",
        "print(lowerword)\n",
        "\n",
        "words = lowerword\n",
        "print(\"Word size before stopwords: \", len(words))\n",
        "\n",
        "\n",
        "stop words to remove\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "print(\"Word size before stopwords: \", len(words))\n",
        "print(words)\n",
        "\n",
        "print(\"=\"*50)\n",
        "words2 = [w for w in words if w not in stopwords.words('english')]\n",
        "print(words2)\n",
        "print(\"Word size after removing stopwords: \", len(words2))"
      ],
      "metadata": {
        "id": "kmlCKaV9YXTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "fd = nltk.FreqDist(words2)\n",
        "fd\n",
        "print('Word type: %d'%len(fd),'개')\n",
        "\n",
        "fwords = nltk.FreqDist(words2).most_common()\n",
        "print(fwords[:5])\n",
        "이거에 대한 결과값\n",
        "Word type: 213 개\n",
        "[('light', 22), ('ocean', 6), ('shrimp', 5), ('life', 4), ('organisms', 4)]"
      ],
      "metadata": {
        "id": "l0ziyrVkWpZ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One time occurrences:\n",
        "freq_num1 = [item[1] for item in fwords]\n",
        "num1 = freq_num1.count(1);\n",
        "print('Number of words that occur only once: %d'%num1)\n",
        "print('The rest: %d'%(213-num1))\n",
        "\n",
        "# nth word that occurs more than 2\n",
        "i=0\n",
        "for n in freq_num1:\n",
        "  if n >2:\n",
        "#    print(n)\n",
        "    i += 1\n",
        "print('몇 번째 단어까지 2회 초과 빈도? %d'%i, '번째')\n",
        "\n",
        "\n",
        "이거에 대한 결과\n",
        "Number of words that occur only once: 164\n",
        "The rest: 49\n",
        "몇 번째 단어까지 2회 초과 빈도? 16 번째"
      ],
      "metadata": {
        "id": "G5FeP2aUaqin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "빈번도 체크하기\n",
        "\n",
        "import csv\n",
        "fwords = nltk.FreqDist(words2).most_common()\n",
        "\n",
        "List_columns = ['Word', 'Freqeuncy']\n",
        "List_rows = fwords\n",
        "with open('Ch02_wordlist.csv', 'w') as csvfile:\n",
        "    write = csv.writer(csvfile)\n",
        "    write.writerow(List_columns)\n",
        "    write.writerows(List_rows)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"Ch02_wordlist.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "IzUtGvoTa3pk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "gradio: machine learning model\n",
        "\n",
        "!pip install gradio\n",
        "\n",
        "예\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!\"\n",
        "\n",
        "demo = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "\n",
        "demo.launch()\n",
        "\n",
        "\n",
        "날짜 세기 어플\n",
        "\n",
        "import gradio as gr\n",
        "from datetime import datetime\n",
        "\n",
        "def remaining_days(future_date: str):\n",
        "    try:\n",
        "        future_date = datetime.strptime(future_date, '%Y-%m-%d')\n",
        "    except ValueError:\n",
        "        return \"Invalid date format. Please use 'YYYY-MM-DD'\"\n",
        "\n",
        "    current_date = datetime.now()\n",
        "\n",
        "    remaining = future_date - current_date\n",
        "    return remaining.days\n",
        "\n",
        "iface = gr.Interface(fn=remaining_days,\n",
        "                     inputs=gr.inputs.Textbox(label=\"Input a future date (YYYY-MM-DD)\"),\n",
        "                     outputs=\"number\")\n",
        "iface.launch(share=True)\n",
        "\n",
        "\n",
        "\n",
        "오디오로 만들기\n",
        "\n",
        "import gradio as gr\n",
        "from gtts import gTTS\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "def text_to_speech(text):\n",
        "    tts = gTTS(text=text, lang='en')\n",
        "    mp3_filename = \"voice.mp3\"\n",
        "    wav_filename = \"voice.wav\"\n",
        "    tts.save(mp3_filename)\n",
        "\n",
        "    # Convert from MP3 to WAV\n",
        "    audio = AudioSegment.from_mp3(mp3_filename)\n",
        "    audio.export(wav_filename, format=\"wav\")\n",
        "\n",
        "    return wav_filename\n",
        "\n",
        "iface = gr.Interface(fn=text_to_speech,\n",
        "                     inputs=gr.inputs.Textbox(),\n",
        "                     outputs=gr.outputs.Audio(type=\"filepath\"))\n",
        "iface.launch(share=True)\n"
      ],
      "metadata": {
        "id": "hMwk0OIPbOmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "grade check\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# The 10 most popular baby names\n",
        "popular_baby_names = [\"Liam\", \"Emma\", \"Noah\", \"Olivia\", \"Ava\", \"Isabella\", \"Sophia\", \"Mia\", \"Charlotte\", \"Amelia\"]\n",
        "\n",
        "# Create lists for the data\n",
        "names = popular_baby_names\n",
        "english_grades = [random.randint(0, 100) for _ in range(10)]\n",
        "math_grades = [random.randint(0, 100) for _ in range(10)]\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'Name': names,\n",
        "    'English': english_grades,\n",
        "    'Math': math_grades,\n",
        "})\n",
        "\n",
        "print(df)\n",
        "\n",
        "밑에꺼는 이름 넣으면 output이 나온\n",
        "\n",
        "# !pip install gradio\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "def check_grades(name):\n",
        "    name = name.strip().lower()  # remove extra white spaces and convert to lower case\n",
        "    df['Name'] = df['Name'].str.strip().str.lower()  # do the same for names in DataFrame\n",
        "    if name in df['Name'].values:\n",
        "        english_grade = df.loc[df['Name'] == name, 'English'].values[0]\n",
        "        math_grade = df.loc[df['Name'] == name, 'Math'].values[0]\n",
        "        return f\"English Grade: {english_grade}, Math Grade: {math_grade}\"\n",
        "    else:\n",
        "        return \"Name not found in the DataFrame.\"\n",
        "\n",
        "\n",
        "iface = gr.Interface(fn=check_grades,\n",
        "                     inputs=gr.inputs.Textbox(lines=1, placeholder='Enter a name...'),\n",
        "                     outputs=\"text\")\n",
        "iface.launch()\n",
        "\n"
      ],
      "metadata": {
        "id": "vx2c_Pg4cxgH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "유튜브 영상 틀기\n",
        "!pip install gtts\n",
        "from gtts import gTTS\n",
        "from IPython.display import Audio, YouTubeVideo\n",
        "\n",
        "YouTubeVideo(\"_lBbs0kpYRs\", width=800, height=600)\n",
        "\n",
        "오디오로 읽어주기\n",
        "txt = \"He was heartbroken, realizing the mistake he had made.\"\n",
        "tts(txt)\n",
        "Audio('sample.mp3')\n",
        "\n",
        "\n",
        "\n",
        "!pip install openai\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive'\n",
        "\n",
        "import openai\n",
        "openai.api_key = input('openai API key here')\n",
        "\n",
        "\n",
        "한국어로 읽기\n",
        "ktts(\"옛날에 보물을 세상에서 무엇보다 좋아하는 마이다스라는 왕이 살고 있었습니다.\")\n",
        "Audio(\"Ksample.mp3\")"
      ],
      "metadata": {
        "id": "47m1iOLsdGMe"
      }
    }
  ]
}